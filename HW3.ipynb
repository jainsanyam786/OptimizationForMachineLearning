{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "We will read dataset that is about the Simmons stores. The data contains following information.\n",
    "\n",
    "    1.UsesCoupon: Whether a customer uses a coupon provided by the stores.\n",
    "    2.HasCard: Whether the customer has a store card or not.\n",
    "    3.Spends: The total amount spent by the customer in the last year in the unit of $1000.\n",
    "    4.Customer: The id of the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "storeData <- read.csv('simmons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Customer</th><th scope=col>HasCard</th><th scope=col>Spends</th><th scope=col>UsesCoupon</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>0        </td><td>8.5815985</td><td>1        </td></tr>\n",
       "\t<tr><td>2        </td><td>0        </td><td>1.4640473</td><td>0        </td></tr>\n",
       "\t<tr><td>3        </td><td>0        </td><td>3.4647250</td><td>0        </td></tr>\n",
       "\t<tr><td>4        </td><td>1        </td><td>0.8019791</td><td>1        </td></tr>\n",
       "\t<tr><td>5        </td><td>0        </td><td>9.9601634</td><td>1        </td></tr>\n",
       "\t<tr><td>6        </td><td>1        </td><td>7.9306165</td><td>1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Customer & HasCard & Spends & UsesCoupon\\\\\n",
       "\\hline\n",
       "\t 1         & 0         & 8.5815985 & 1        \\\\\n",
       "\t 2         & 0         & 1.4640473 & 0        \\\\\n",
       "\t 3         & 0         & 3.4647250 & 0        \\\\\n",
       "\t 4         & 1         & 0.8019791 & 1        \\\\\n",
       "\t 5         & 0         & 9.9601634 & 1        \\\\\n",
       "\t 6         & 1         & 7.9306165 & 1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Customer | HasCard | Spends | UsesCoupon |\n",
       "|---|---|---|---|\n",
       "| 1         | 0         | 8.5815985 | 1         |\n",
       "| 2         | 0         | 1.4640473 | 0         |\n",
       "| 3         | 0         | 3.4647250 | 0         |\n",
       "| 4         | 1         | 0.8019791 | 1         |\n",
       "| 5         | 0         | 9.9601634 | 1         |\n",
       "| 6         | 1         | 7.9306165 | 1         |\n",
       "\n"
      ],
      "text/plain": [
       "  Customer HasCard Spends    UsesCoupon\n",
       "1 1        0       8.5815985 1         \n",
       "2 2        0       1.4640473 0         \n",
       "3 3        0       3.4647250 0         \n",
       "4 4        1       0.8019791 1         \n",
       "5 5        0       9.9601634 1         \n",
       "6 6        1       7.9306165 1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(storeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spends are already reduced in given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Store data 1000 4"
     ]
    }
   ],
   "source": [
    "cat(\"Size of Store data\",dim.data.frame(storeData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Fit a logistic regression model with the UsesCoupon as the response and other variables Spends and HasCard as potential predictors using gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Form the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>UsesCoupon</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       " UsesCoupon\\\\\n",
       "\\hline\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| UsesCoupon |\n",
       "|---|\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     UsesCoupon\n",
       "[1,] 1         \n",
       "[2,] 0         \n",
       "[3,] 0         \n",
       "[4,] 1         \n",
       "[5,] 1         \n",
       "[6,] 1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ones</th><th scope=col>HasCard</th><th scope=col>Spends</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>0        </td><td>8.5815985</td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>1.4640473</td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>3.4647250</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.8019791</td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>9.9601634</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>7.9306165</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " Ones & HasCard & Spends\\\\\n",
       "\\hline\n",
       "\t 1         & 0         & 8.5815985\\\\\n",
       "\t 1         & 0         & 1.4640473\\\\\n",
       "\t 1         & 0         & 3.4647250\\\\\n",
       "\t 1         & 1         & 0.8019791\\\\\n",
       "\t 1         & 0         & 9.9601634\\\\\n",
       "\t 1         & 1         & 7.9306165\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ones | HasCard | Spends |\n",
       "|---|---|---|\n",
       "| 1         | 0         | 8.5815985 |\n",
       "| 1         | 0         | 1.4640473 |\n",
       "| 1         | 0         | 3.4647250 |\n",
       "| 1         | 1         | 0.8019791 |\n",
       "| 1         | 0         | 9.9601634 |\n",
       "| 1         | 1         | 7.9306165 |\n",
       "\n"
      ],
      "text/plain": [
       "     Ones HasCard Spends   \n",
       "[1,] 1    0       8.5815985\n",
       "[2,] 1    0       1.4640473\n",
       "[3,] 1    0       3.4647250\n",
       "[4,] 1    1       0.8019791\n",
       "[5,] 1    0       9.9601634\n",
       "[6,] 1    1       7.9306165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y <- as.matrix(storeData$UsesCoupon)\n",
    "colnames(y) <- c(\"UsesCoupon\")\n",
    "ones <- matrix(rep(1,nrow(y)), nrow = nrow(y), ncol = 1)\n",
    "# data matrix\n",
    "A <- cbind(ones,storeData$HasCard,storeData$Spends)\n",
    "colnames(A) <- c(\"Ones\",\"HasCard\",\"Spends\")\n",
    "head(y)\n",
    "head(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Modelling the success probability as\n",
    "$\\hat{y} = \\sigma(Ax) \\enspace  \\text{where} \\enspace  \\sigma{(z)} = \\Large\\frac{e^{z}}{(1 + e^{z})} $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is the data mtrix of dimension 1000 x 3 and x is the coffiecient matrix of dimension 3 x 1.\n",
    "# This function will return will return matric of dimension with 1000 x 1 with yi = sigmoid(Aixi)\n",
    "sigmoid <- function(x,A){\n",
    "    Ax <- A %*% x\n",
    "    yhat <- apply(Ax,1, function (var) exp(var)/(1 + exp(var)))\n",
    "    yhat <- as.matrix(yhat)\n",
    "    colnames(yhat) <- c(\"Predicted_UsesCoupon\")              \n",
    "    return (yhat)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculating gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is the data mtrix of dimension 1000 x 3, y is the output matrix of dimension 1000 x 1,\n",
    "# yhat is the predicted output matrix of dimension 1000 x 1\n",
    "# This function will compute and return will gradient matrix with dim 3 x 1\n",
    "gradient <- function(A,y,yhat){\n",
    "    N <- length(y)\n",
    "    deltafx = matrix(rep(0,ncol(A)), nrow = ncol(A), ncol = 1)\n",
    "    for(j in seq(nrow(deltafx))){\n",
    "        sum <- 0\n",
    "        for(i in seq(nrow(A))){\n",
    "            temp <- (yhat[i] - y[i]) * A[i,j]\n",
    "            sum <- sum + temp\n",
    "        }\n",
    "        deltafx[j] <- sum/N\n",
    "    }\n",
    "    rownames(deltafx) <- c(\"deltafx1\", \"deltafx2\", \"deltafx3\")\n",
    "    return (deltafx)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defination of function for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is the data mtrix of dimension 1000 x 3, y is the output matrix of dimension 1000 x 1,\n",
    "# alpha is the learnig rate,  thres is the threshold for gradient norm for stopping, mxi is maximum iterations\n",
    "# This function do gradient descent and give optimimum cofficients\n",
    "gradientDescent <- function(y,A,x,alpha,thrs,maxi){\n",
    "    converged<-FALSE\n",
    "    i<-1\n",
    "    x1<-x\n",
    "     while((!converged  && i <= maxi))\n",
    "            {\n",
    "                yhat <-  sigmoid(x1,A)\n",
    "                deltafx <- gradient(A,y,yhat)\n",
    "                if(is.infinite(deltafx) || is.nan(norm(deltafx,type = \"2\"))){\n",
    "                    break\n",
    "                }\n",
    "                x1 <- x1 - (alpha*deltafx)\n",
    "                converged <- (norm(deltafx,type = \"2\") <= thrs)\n",
    "                i <- i+1\n",
    "            }\n",
    "\n",
    "    return (list(\"x1\"= x1,\"iteration\" = i-1,\"converged\" = converged))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>10.0</th><th scope=col> 5.0</th><th scope=col> 1.0</th><th scope=col> 0.5</th><th scope=col> 0.1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>x1</th><td>-15.367439</td><td> -8.479330</td><td> -4.929665</td><td> -4.925239</td><td> -4.920445</td></tr>\n",
       "\t<tr><th scope=row>x2</th><td> 17.255413</td><td> 10.574735</td><td>  6.568382</td><td>  6.562942</td><td>  6.557031</td></tr>\n",
       "\t<tr><th scope=row>x3</th><td>  3.758761</td><td>  2.140135</td><td>  1.284105</td><td>  1.283100</td><td>  1.282012</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & 10.0 &  5.0 &  1.0 &  0.5 &  0.1\\\\\n",
       "\\hline\n",
       "\tx1 & -15.367439 &  -8.479330 &  -4.929665 &  -4.925239 &  -4.920445\\\\\n",
       "\tx2 &  17.255413 &  10.574735 &   6.568382 &   6.562942 &   6.557031\\\\\n",
       "\tx3 &   3.758761 &   2.140135 &   1.284105 &   1.283100 &   1.282012\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 10.0 |  5.0 |  1.0 |  0.5 |  0.1 |\n",
       "|---|---|---|---|---|---|\n",
       "| x1 | -15.367439 |  -8.479330 |  -4.929665 |  -4.925239 |  -4.920445 |\n",
       "| x2 |  17.255413 |  10.574735 |   6.568382 |   6.562942 |   6.557031 |\n",
       "| x3 |   3.758761 |   2.140135 |   1.284105 |   1.283100 |   1.282012 |\n",
       "\n"
      ],
      "text/plain": [
       "   10.0        5.0        1.0        0.5        0.1      \n",
       "x1 -15.367439  -8.479330  -4.929665  -4.925239  -4.920445\n",
       "x2  17.255413  10.574735   6.568382   6.562942   6.557031\n",
       "x3   3.758761   2.140135   1.284105   1.283100   1.282012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>10.0</th><th scope=col> 5.0</th><th scope=col> 1.0</th><th scope=col> 0.5</th><th scope=col> 0.1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>105 </td><td>150 </td><td>339 </td><td>679 </td><td>3394</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       " 10.0 &  5.0 &  1.0 &  0.5 &  0.1\\\\\n",
       "\\hline\n",
       "\t 105  & 150  & 339  & 679  & 3394\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 10.0 |  5.0 |  1.0 |  0.5 |  0.1 |\n",
       "|---|---|---|---|---|\n",
       "| 105  | 150  | 339  | 679  | 3394 |\n",
       "\n"
      ],
      "text/plain": [
       "     10.0  5.0  1.0  0.5  0.1\n",
       "[1,] 105  150  339  679  3394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'10.0'</li>\n",
       "\t<li>' 5.0'</li>\n",
       "\t<li>' 1.0'</li>\n",
       "\t<li>' 0.5'</li>\n",
       "\t<li>' 0.1'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '10.0'\n",
       "\\item ' 5.0'\n",
       "\\item ' 1.0'\n",
       "\\item ' 0.5'\n",
       "\\item ' 0.1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '10.0'\n",
       "2. ' 5.0'\n",
       "3. ' 1.0'\n",
       "4. ' 0.5'\n",
       "5. ' 0.1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"10.0\" \" 5.0\" \" 1.0\" \" 0.5\" \" 0.1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#running gradient descent on data with different learning rate\n",
    "alphas <- c(10,5.0,1,0.5,0.1,0.01)\n",
    "thres <- 10**(-2)\n",
    "maxiter <- 10000\n",
    "successalphs <- c()\n",
    "iternations <- list()\n",
    "xsfull <- list()\n",
    "x = matrix(rep(0,ncol(A)), nrow = ncol(A), ncol = 1)\n",
    "rownames(x) <- c(\"x1\", \"x2\", \"x3\")\n",
    "row = 1\n",
    "for (alpha in alphas) {\n",
    "    answer <- gradientDescent(y,A,x,alpha,thres,maxiter)\n",
    "        if (answer$converged){\n",
    "        successalphs <- append(successalphs,alpha)\n",
    "        xsfull[[row]] <- answer$x\n",
    "        iternations[[row]] <- answer$iteration\n",
    "        row = row+1\n",
    "    }\n",
    "    }\n",
    "successalphs <- format(successalphs, scientific = FALSE)\n",
    "xsfull <- do.call(cbind, xsfull)\n",
    "iternations <- do.call(cbind, iternations)\n",
    "\n",
    "colnames(xsfull)<- successalphs\n",
    "colnames(iternations)<- successalphs\n",
    "modifiedxs <- format(xsfull, scientific = FALSE)\n",
    "modifiedxs\n",
    "iternations\n",
    "successalphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Interation vs alpha\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot(iternations, main=\"Interation vs alpha\", names.arg = successalphs,\n",
    "        ylab = \"Interations\", ylim = c(0,max(iternations)+20), xlab = \"Alpha\", axes = FALSE)\n",
    "ylabel <- seq(0, max(iternations)+20, by = max(iternations)%/%10)\n",
    "axis(2, at = ylabel, las = 1)\n",
    "box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>x1</th><td>-4.929665</td></tr>\n",
       "\t<tr><th scope=row>x2</th><td> 6.568382</td></tr>\n",
       "\t<tr><th scope=row>x3</th><td> 1.284105</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\tx1 & -4.929665\\\\\n",
       "\tx2 &  6.568382\\\\\n",
       "\tx3 &  1.284105\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| x1 | -4.929665 |\n",
       "| x2 |  6.568382 |\n",
       "| x3 |  1.284105 |\n",
       "\n"
      ],
      "text/plain": [
       "   [,1]     \n",
       "x1 -4.929665\n",
       "x2  6.568382\n",
       "x3  1.284105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# selecting cofficients for learning rate 0.5 \n",
    "optimumx <- as.matrix(xsfull[,3])\n",
    "optimumx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Predict the probiblities of using coupons for given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualSpending <- c(1000,2000,3000,4000,5000,6000,7000)\n",
    "# diving spending by 1000 to get smaller values\n",
    "annualSpendingR <- annualSpending/1000\n",
    "ones <- rep(1,length(annualSpendingR))\n",
    "\n",
    "HasCardYes <- rep(1,length(annualSpendingR))\n",
    "HasCardNo <- rep(0,length(annualSpendingR))\n",
    "\n",
    "dataMatrixYes <- cbind(ones,HasCardYes,annualSpendingR)\n",
    "dataMatrixNo <- cbind(ones,HasCardNo,annualSpendingR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatYes <- sigmoid(x = optimumx,A = dataMatrixYes)\n",
    "yhatNo <- sigmoid(x = optimumx,A = dataMatrixNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionTable <- cbind(annualSpending,yhatYes,yhatNo)\n",
    "colnames(PredictionTable) <- c(\"Annual Spending\",\"Credit Card Yes\", \"Credit Card No\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Annual Spending</th><th scope=col>Credit Card Yes</th><th scope=col>Credit Card No</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1000      </td><td>0.9489631 </td><td>0.02544255</td></tr>\n",
       "\t<tr><td>2000      </td><td>0.9853265 </td><td>0.08615953</td></tr>\n",
       "\t<tr><td>3000      </td><td>0.9958933 </td><td>0.25400773</td></tr>\n",
       "\t<tr><td>4000      </td><td>0.9988595 </td><td>0.55150524</td></tr>\n",
       "\t<tr><td>5000      </td><td>0.9996839 </td><td>0.81620721</td></tr>\n",
       "\t<tr><td>6000      </td><td>0.9999125 </td><td>0.94130784</td></tr>\n",
       "\t<tr><td>7000      </td><td>0.9999758 </td><td>0.98302794</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " Annual Spending & Credit Card Yes & Credit Card No\\\\\n",
       "\\hline\n",
       "\t 1000       & 0.9489631  & 0.02544255\\\\\n",
       "\t 2000       & 0.9853265  & 0.08615953\\\\\n",
       "\t 3000       & 0.9958933  & 0.25400773\\\\\n",
       "\t 4000       & 0.9988595  & 0.55150524\\\\\n",
       "\t 5000       & 0.9996839  & 0.81620721\\\\\n",
       "\t 6000       & 0.9999125  & 0.94130784\\\\\n",
       "\t 7000       & 0.9999758  & 0.98302794\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Annual Spending | Credit Card Yes | Credit Card No |\n",
       "|---|---|---|\n",
       "| 1000       | 0.9489631  | 0.02544255 |\n",
       "| 2000       | 0.9853265  | 0.08615953 |\n",
       "| 3000       | 0.9958933  | 0.25400773 |\n",
       "| 4000       | 0.9988595  | 0.55150524 |\n",
       "| 5000       | 0.9996839  | 0.81620721 |\n",
       "| 6000       | 0.9999125  | 0.94130784 |\n",
       "| 7000       | 0.9999758  | 0.98302794 |\n",
       "\n"
      ],
      "text/plain": [
       "     Annual Spending Credit Card Yes Credit Card No\n",
       "[1,] 1000            0.9489631       0.02544255    \n",
       "[2,] 2000            0.9853265       0.08615953    \n",
       "[3,] 3000            0.9958933       0.25400773    \n",
       "[4,] 4000            0.9988595       0.55150524    \n",
       "[5,] 5000            0.9996839       0.81620721    \n",
       "[6,] 6000            0.9999125       0.94130784    \n",
       "[7,] 7000            0.9999758       0.98302794    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PredictionTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Comment on a marketing strategy based on the table above for maximizing the number of customers using your store coupons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using above table as reference, as CEO I can have two strategies\n",
    "##### 1. I can encourage the customers without store card and with annual spending less than \\$6000 to enroll for store credit card.\n",
    "\n",
    "This on the basis of observation that the customers with store card use coupons with high probability irrespective of annual spending.\n",
    "      \n",
    "##### 2. I can encourage the customers to increase their annual spening in my stores.\n",
    "\n",
    "This on the basis of observation that the customers with annual speding more than \\$6000 use coupons with high probability irrespective of store card.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Implement Polyak's momentum method to solve the logistic regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is the data mtrix of dimension 1000 x 3, y is the output matrix of dimension 1000 x 1,\n",
    "# alpha is the learnig rate,  thres is the threshold for gradient norm for stopping, mxi is maximum iterations\n",
    "# This function do gradient descent and give optimimum cofficients\n",
    "polyakMomentum <- function(y,A,x,alpha,beta,thrs,maxi) {\n",
    "    converged<-FALSE\n",
    "    i <- 1\n",
    "    x1 <- x\n",
    "    Z <- matrix(rep(0,ncol(A)), nrow = ncol(A), ncol = 1)\n",
    "     while((!converged  && i <= maxi))\n",
    "            {\n",
    "                yhat <-  sigmoid(x1,A)\n",
    "                deltafx <- gradient(A,y,yhat)\n",
    "                if(is.infinite(deltafx) ||is.nan(deltafx) || is.nan(norm(deltafx,type = \"2\"))){\n",
    "                    break\n",
    "                }\n",
    "                # polyakMomentum \n",
    "                Z <- beta*Z + deltafx\n",
    "                x1 <- x1 - (alpha*Z)\n",
    "                converged <- (norm(deltafx,type = \"2\") <= thrs)\n",
    "                i <- i+1\n",
    "            }\n",
    "\n",
    "    return (list(\"x1\"= x1,\"iteration\" = i-1,\"converged\" = converged))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0.1</th><th scope=col>0.3</th><th scope=col>0.5</th><th scope=col>0.7</th><th scope=col>0.9</th><th scope=col>1.0</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>x1</th><td> -4.926078</td><td> -4.924722</td><td> -4.931246</td><td> -4.931343</td><td> -6.540701</td><td>-28.411975</td></tr>\n",
       "\t<tr><th scope=row>x2</th><td>  6.563981</td><td>  6.562334</td><td>  6.570435</td><td>  6.570860</td><td>  8.533689</td><td> 34.507292</td></tr>\n",
       "\t<tr><th scope=row>x3</th><td>  1.283290</td><td>  1.282982</td><td>  1.284462</td><td>  1.284480</td><td>  1.733906</td><td>  6.684101</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & 0.1 & 0.3 & 0.5 & 0.7 & 0.9 & 1.0\\\\\n",
       "\\hline\n",
       "\tx1 &  -4.926078 &  -4.924722 &  -4.931246 &  -4.931343 &  -6.540701 & -28.411975\\\\\n",
       "\tx2 &   6.563981 &   6.562334 &   6.570435 &   6.570860 &   8.533689 &  34.507292\\\\\n",
       "\tx3 &   1.283290 &   1.282982 &   1.284462 &   1.284480 &   1.733906 &   6.684101\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0.1 | 0.3 | 0.5 | 0.7 | 0.9 | 1.0 |\n",
       "|---|---|---|---|---|---|---|\n",
       "| x1 |  -4.926078 |  -4.924722 |  -4.931246 |  -4.931343 |  -6.540701 | -28.411975 |\n",
       "| x2 |   6.563981 |   6.562334 |   6.570435 |   6.570860 |   8.533689 |  34.507292 |\n",
       "| x3 |   1.283290 |   1.282982 |   1.284462 |   1.284480 |   1.733906 |   6.684101 |\n",
       "\n"
      ],
      "text/plain": [
       "   0.1        0.3        0.5        0.7        0.9        1.0       \n",
       "x1  -4.926078  -4.924722  -4.931246  -4.931343  -6.540701 -28.411975\n",
       "x2   6.563981   6.562334   6.570435   6.570860   8.533689  34.507292\n",
       "x3   1.283290   1.282982   1.284462   1.284480   1.733906   6.684101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0.1</th><th scope=col>0.3</th><th scope=col>0.5</th><th scope=col>0.7</th><th scope=col>0.9</th><th scope=col>1.0</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>611</td><td>474</td><td>338</td><td>199</td><td>60 </td><td>61 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllll}\n",
       " 0.1 & 0.3 & 0.5 & 0.7 & 0.9 & 1.0\\\\\n",
       "\\hline\n",
       "\t 611 & 474 & 338 & 199 & 60  & 61 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.1 | 0.3 | 0.5 | 0.7 | 0.9 | 1.0 |\n",
       "|---|---|---|---|---|---|\n",
       "| 611 | 474 | 338 | 199 | 60  | 61  |\n",
       "\n"
      ],
      "text/plain": [
       "     0.1 0.3 0.5 0.7 0.9 1.0\n",
       "[1,] 611 474 338 199 60  61 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'0.1'</li>\n",
       "\t<li>'0.3'</li>\n",
       "\t<li>'0.5'</li>\n",
       "\t<li>'0.7'</li>\n",
       "\t<li>'0.9'</li>\n",
       "\t<li>'1.0'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '0.1'\n",
       "\\item '0.3'\n",
       "\\item '0.5'\n",
       "\\item '0.7'\n",
       "\\item '0.9'\n",
       "\\item '1.0'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '0.1'\n",
       "2. '0.3'\n",
       "3. '0.5'\n",
       "4. '0.7'\n",
       "5. '0.9'\n",
       "6. '1.0'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"0.1\" \"0.3\" \"0.5\" \"0.7\" \"0.9\" \"1.0\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "betas <- c(0.1,0.3,0.5,0.7,0.9,1)\n",
    "alpha <- 0.5\n",
    "thres <- 10**(-2)\n",
    "maxiter <- 10000\n",
    "successbetas <- c()\n",
    "iternations <- list()\n",
    "xsfull <- list()\n",
    "x = matrix(rep(0,ncol(A)), nrow = ncol(A), ncol = 1)\n",
    "rownames(x) <- c(\"x1\", \"x2\", \"x3\")\n",
    "row = 1\n",
    "for (beta in betas) {\n",
    "    answer <- polyakMomentum(y,A,x,alpha,beta,thres,maxiter)\n",
    "        if (answer$converged){\n",
    "        successbetas <- append(successbetas,beta)\n",
    "        xsfull[[row]] <- answer$x\n",
    "        iternations[[row]] <- answer$iteration\n",
    "        row = row+1\n",
    "    }\n",
    "    }\n",
    "successbetas <- format(successbetas, scientific = FALSE)\n",
    "xsfull <- do.call(cbind, xsfull)\n",
    "iternations <- do.call(cbind, iternations)\n",
    "\n",
    "colnames(xsfull)<- successbetas\n",
    "colnames(iternations)<- successbetas\n",
    "modifiedxs <- format(xsfull, scientific = FALSE)\n",
    "modifiedxs\n",
    "iternations\n",
    "successbetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAAgAElEQVR4nO2d2aKiMBAFw+pyAf//b4dVQaEB6UbIVD1c48ZhTNcAIYp7AMBm\n3K9XAMAHEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlA\nAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRA\nJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEEkf58Y/\n1WT5IhJxQV8hL2zFusEYiKTPeMn+BYs/6+6lu4m0Yt1gHD5AfcZLdoUV3Ut3E0k16P+ED1Af\nNZFUQSRT+AD1acuyurlHziVZc8e1jxdp4II0716ahy4tW7e4bIfVw6+XPuv7npTN5P5a/HO5\nLX/l3bpRvvCvjLiUz7v49r5W19AFSZPcW43eur3WYnwhMAUi6fMSKW1KNOsXax40zb/2NaFz\n0eMRtS8oH/4UqXsyfnwstyN47g0Gr4hqwf21inrJvdV4BfbWYnwhMAUi6fMSqSXpF2tXn8Hr\nNbfHtazX4vFIK1k+RIqfC4o/lttRvrPaYN1dtXlLqkU+ilKL62Ct+sm91XgG9tdifCEwBSLp\n8xIpuNcF6XqPNsVaNGVabybK0n2Um6X89SI3GGwo5XDX8i0X18jyttyGrNEq6TYx1dKKcnM3\nWKvqbfegTv5Yjcf7WowuBKZAJH1e5lR1XwxFKjcvRXM3fr3m7a1DkZJum5A2srwttyWslttW\nfbW1SQbL7UXd6+SP1fhYi9GFwBSIpM/QnLe7wz0s19ZzSX5LIzcm0vM1+dizHZdq23Jz7tK0\n3YcGz5d325vhanysxehCYApE0mehSINxuVs48ujba0a3Vx15NSoQtftmaSdJ/rFWHyL1FzlY\ni7GFwBSIpI8oUjAo/2cFl40wuWZzW6Tgc7kdpUTZ83imuDUDcL0Rt+diuh23z9UYrsXYQmAK\nRNJHFCkeHBV1rwnbR8dEij+PkQbvbSktiAcjbPfhcIRrxhVex0ifqzFci7GFwBR8SPpMi1TU\n9R781TfR52t6W6Ti+ejIqF3/PR1FvfWoNzrhcyQhGKxVZVI1ancZW43ibS1GFwJTIJI+4yJV\no2Dp43UCpz4v2r0mqp+ritz1Xto++zxN2pw4mhCpHg9v9sJK9aK8Hi5IB2vVHfQU76vRBg7W\nYnQhMAUi6TMuUlfn97aA0/5r/roarwu7e2lPs5dHkyLdu5231zjB28yG9sxuNwr+Wo02cLgW\nYwuBKRBJn3GRqsOS2oQiLfea4vvguUdW1nKQZHlzXiceHg2VRyrBcK7d4L293G4svT60ia5v\nzz6u1RS951y712p0gcO1GFkITIFIAAogEoACiASgACIBKIBIAAogEoACiASgACIBKIBIAAog\nEoACiASgACIBKIBIAAogEoACiASgACIBKIBIAAogEoACiASgACIBKIBIAAogEoACiASgACIB\nKIBIAAogEoACiASgACIBKIBIAAogEoACiASgACIBKIBIAAogEoACiASgACIBKIBIAAogEoAC\niASgwA4iOYCT8UWV64vzgwgATRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFE\nAlAAkQAUQCQABRAJQAFrkbLEuSRv71y7t6aBC9JCda0AfomxSPf6qxpB40zWfWkjqh8NVdcK\n4JcYixQE2aOIXVq1s6AV6c+Vj5b3/jTXCuCX2Ip0qxUqXPCo9uuiVqTU3evnLpprBfBLbEVK\nXPZ6W/poRYpdddCUuVhzrQB+ia1IoXtcApfUh0jZoxNpeLMq4mDfugdosRXJubgebHjeHbl5\nvXZBTbvADkSC77EWqRpsSLqjIYUtEiLBIbEWqTpGyruRbkQCX7EWqX/T3QaIBL5hK1I8KlIz\napd/M2qHSHBMbEW61GeMche173S9R+/Nadp1EYgEx8RWpPLoqKgGG27tOzfPbEAkOCbGU4Qu\n9WB21L2zfWs4eHRNBCLBMbGe/X2PXPDchetEKurZ399EIBIck5N9HwmR4JggEiKBAoiESKAA\nIiESKIBIiAQKIBIigQKIhEigACIhEiiASIgECiASIoECiIRIoAAiIRIogEiIBAogEiKBAoiE\nSKAAIiESKIBIiAQKIBIigQKIhEigACIhEiiASIgECiASIoECiIRIoAAiIRIogEiIBAogEiKB\nAoiESKAAIiESKIBIiAQKIBIigQKIhEigACIhEiiASIgECiASIoECiIRIoAAiIRIogEiIBAog\nEiKBAoiESKAAIiESKIBIiAQKIBIigQKIhEigACIhEihgLJJr6O7+ta00cNH9mwhEgmNiK1I2\nFKloizWqH7x8EYFIcEysRYr7d+NGqauLikeRuGx9BCLBMbEV6TrY7NzabVPk/sq/uUvXRyAS\nHBNrka6vO7mLGpHaXT0XrY9AJDgmtiLF7p64oN3yRC4fijS9IESCk2EtUk296bm4W+tO6PJH\nNYI3XJDrM5mNSHBIbEVypTyPIq128Opxh8aQi4uLRxaxRQJ/2OOEbOHCcjMUFM+9uaDa6MSI\nBP6wy8yGUpnE3R9PkYrywOnCMRJ4xF4ifR7+ZNV2am0EIsExsRUpcOX+3CMvD4/6IjWPXocn\na5dFIBIcE1uR0uqka5G6bl5dsz1KXfJ4/IXVQMTaCESCY2IrUlEPK7ymMDQitY9Ob5AQCc6G\n8TFSkQYufM1uaI+Q8qTUiNnf4BF8HwmRQAFEQiRQAJEQCRRAJEQCBRAJkUABREIkUACREAkU\nQCREAgUQCZFAAURCJFAAkRAJFEAkRAIFEAmRQAFEQiRQAJEQCRRAJEQCBRAJkUABREIkUACR\nEAkUQCREAgUQCZFAAURCJFAAkRAJFEAkRAIFEAmRQAFEQiRQAJEQCRRAJEQCBRAJkUABREIk\nUACREAkUQCREAgUQCZFAAURCJFAAkRAJFEAkRAIFEAmRQAFEQiRQAJEQCRRAJEQCBRAJkUAB\nREIkUACREAkUQCREAgUQCZFAgR1E+mveUKSBC9LirbkyApHgmNiLVDQVmgeuIsgHzbURiATH\nxF6k2NVvSFxa/k1dMmiujUAkOCbmIt1cI1Lzt77pNddGIBIcE2uRchc1wrR16oJBc20EIsEx\nsRYpcnkj0qXdn7sMmmsjEAmOibFIF3frduGu1RBDcH1r9hbbZzIbkeCQ2IqUufh5LHSpDbm8\nNVdGIBIcE1uRwqDoRLpW+3NF4q6D5toIRIJjYipS4u6PTqTQVSdgCxcOmmsjEAmOialI/WMe\nhr/BZ3YTqanT4jX8XTD8Df6ww1y7ZsuTumpyXVodHvWaayMQCY7JbiI9onrTFL01V0YgEhyT\n/UR61FO+P5rrIhAJjgnfR0IkUACREAkUQCREAgUQCZFAAURCJFAAkQSRnCWmHyDsDSJJIu2a\nBmcGkYTSRiRYCiIJpY1IsBREEkobkWApiCSUNiLBUhBJKG1EgqUgklDaiARLQSShtBEJloJI\nQmkjEiwFkYTSRiRYCiIJpY1IsBREEkobkWApiCSUNiLBUhBJKG1EgqUgklDaiARLQSShtBEJ\nloJIQmkjEiwFkYTSRiRYCiIJpY1IsBREEkobkWApiCSUNiLBUhBJKG1EgqUgklDaiARLQSSh\ntBEJloJIQmkjEiwFkYTSRiRYCiIJpY1IsBREEkobkWApiCSUNiLBUhBJKG1EgqUgklDaiARL\nQSShtBEJloJIQmkjEiwFkYTSRiRYCiIJpY1IsBREEkobkWApiCSUNiLBUhBJKG1EgqUgklDa\niARL2UGkv/YN19AFaVEtoGN9BCLBMbEXqWhrJq3dCYqXSMH6CESCY2IvUtxseTKXlA5dXdI9\nfnd/6yMQCY6JuUi3dhcubt723J8rgviLCESCY2ItUu6iwbHQ807sii8iEAmOibVIkcv7IhUu\nahqZS7+JQCQ4JsYiXdzt0Rfp6u5N43OD5PpMZu9a2ogES7EVKXPxoy9S3h0YZa9Bh1URiATH\nxFaksBnt7u4WQbtj90i7LdPKCESCY2IqUlLr8hIpCrvWTB0hEpwMU5GGxzx5GOXtE/Uu3zcR\niATHZD+R7t2A3aMac7h+F4FIcEx2mGvXbo96Hj1il30XgUhwTHYTKenv5YXS2VgpApHgmOwm\n0uBwSZj4LUcgEhwTvo8klDYiwVIQSShtRIKlIJJQ2ogES0EkobQRCZaCSEJpIxIsBZGE0kYk\nWAoiCaWNSLAURBJKG5FgKYgklDYiwVIQSShtRIKlIJJQ2ogES0EkobQRCZaCSEJpIxIsBZGE\n0kYkWAoiCaWNSLAURBJKG5FgKYgklDYiwVIQSShtRIKlIJJQ2ogES0EkobQRCZaCSEJpIxIs\nBZGE0kYkWAoiCaWNSLAURBJKG5FgKYgklDYiwVIQSShtRIKlIJJQ2ogES0EkobQRCZaCSEJp\nIxIsBZGE0kYkWAoiCaWNSLAURBJKG5FgKYgklDYiwVIQSShtRIKlIJJQ2ogES0EkobQRCZaC\nSEJpIxIsBZGE0kYkWAoiCaWNSLAURBJKG5FgKYgklDYiwVIQSShtRIKlIJJQ2ogES0EkobQR\nCZaCSEJpIxIsxVikInEuyZp2VrXz9+a6CESCY2IsUuAqapPudTMohs2VEYgEx8RWpNQl1Z+4\nagdB9ihilw6bKyMQCY6JrUiBq7Y6rnrHrfamcMGguTYCkeCY7DHYUBuTuKy732uujUAkOCY7\niJS6a/k3dI9L4JJi2FwbgUhwTMxFurnmWMi5uB5hGDb7i+0zmb1raSMSLMVcpGscuEv1LleN\nMCRVu9dcG4FIcEz2OEZKqn27ZhA8d+GguTYCkeCYbBXpWtqQhy78E95Qj8+1u2vVTa+5dq0Q\nCY7JRpHulQ31WVfJpOpFsRtrrl0rRIJjslGkyN0eWbmPdnPR2Eub80j1TtzF3etmNGiuXStE\ngmOyUaRqq5JVw3Ljm5d6ZkMRV8dIpU1FNcJwGzTXrhUiwTFRECmuNjAT+2nNXLt603MZba5c\nK0SCY7J51y67N7N+JrRIAxdem+Y9ckH60Vy3VogEx2T7YINrTg3d1VbpgUhwOjYPfwf1xIVw\n+njnGxAJTgbfkBVKG5FgKYgklDYiwVIQSShtRIKlbBXpEs5N2P4GRIKTsVGky/w3H74BkeBk\nbBQpcFe1VZmIGD6xa2kjEixFYWaDAYgEJ2OjSLETvjD+PYgEJ2OjSHkQSd+f+BZEgpOxedeO\nwQatNDgziCSUNiLBUjghK5Q2IsFSEEkobUSCpWwW6RaVu3Wx7uRvRIKzsVWkqD1CEr7u+gWI\nBCdjo0hXF1Tf6Lsrz3BAJDgZG0UK29/Dz4Rfe/yC/1IkZ4hm58AYWlOEGP4+choimaO2RZq+\n2NEXIJJ1GCjDMZJQbd6kIZI5jNoJ1eZNGiKZs/08Usx5pMOnIZI5zGwQqs2bNEQyB5GEavMm\nDZHM2SBSc6kjZn+fIA2RzEEkodq8SUMkc9i1E6rNmzREMgeRhGrzJg2RzNGaIhQws+HAaYhk\njpJIOcdIR05DJHM2iHQfzC9m9veB0xDJnC1bpLDvkeqvciGSdRgoo3WMpAsiWYeBMozaCdXm\nTRoimaMl0l+8dU1mI+on7IoNkWADW0VKmdlwgjREMmejSC+PuKr5gdMQyZyNIgXu9ohcnkeO\nUbsDpyGSOQqjdpdya5TpfkUWkazDQBkFke7V7zVwjHTkNEQyZ6NIcblrl7vw8YdIR05DJHM2\ninSvBKp/ACVRW6UHItmHgTJbh78v1b3EuVRpfUYiBk/YFRsiwQaMZzYUpWNJ8xuSjzRwQVpf\ncnb2zBMiWYeBMluPkWa2REFtTG1S9JwkniESIvmG7aTVtDp0Sl01fejPBdkjC6rzTZmbm0+E\nSNZhoMxGkUJXSC8N6qdr29J67sPNXarfOb58u1belDYiecZGkYo4mp/SUP/AfuzyR7sxus7+\nUDgiWYeBMpt37eYnraa1N+0LqpvY3RMXSEdXiGQdBsqYi3Rrh8YHIo397v6iC2N5U9qI5Bnm\nX+y7xkF9SNQTyblbuVOYCjt4iGQdBsrs8Q3ZpDcZ77WxKYTfS0Ek6zBQZrNI97jeW8uFNxTV\naEPwLpI0dI5I1mGgzFaRouaIxgWSSc2BUfWKvHcKCZF2S0MkczaKdHVRUQlxHZ+02pxHqqaH\n199aqia5pq9Hp0/LIpJ1GCizUaTKiXrLMr55qWc2FHF1jNSb2ZBWNhWp8O10RLIOA2UUpggJ\nIrVz7eqB7vDZLJpHhRNJiGQdBsooTBGqHMqmhuDSwIXNMHdRz/5+NkNpdgMiWYeBMjrHSPdg\ndtbP1xHDJ+yKDZFgA1tH7dpZCrq/fYJI5mGgjMp5JBfflFZnNKL/hF2xIRJsYI+ZDYoR3pQ2\nInkGIgnV5k0aIpmjMPxdw6Uvj5yGSOYoicSlLw+dhkjmbBCJS1+eJg2RzNmyReLSl2dJQyRz\ntI6RdEEk6zBQhlE7odq8SUMkcxBJqDZv0hDJnK0iXZ4HSlpr9BExeMKu2BAJNrBRpMuCn+P6\nAkSyDgNlNn+xT3XW91jE8Am7YkMk2ACjdkK1eZOGSOZsFCmWf/v7WxDJOgyU2ShSHiz47e9t\nEcMn7IoNkWADm3ftGGw4QRoimYNIQrV5k4ZI5nBCVqg2b9IQyRxEEqrNmzREMgeRhGrzJg2R\nzNkgkhuyy1p5U9qI5BmIJFSbN2mIZA67dkK1eZOGSOYgklBt3qQhkjmIJFSbN2mIZA4iCdXm\nTRoimYNIQrV5k4ZI5iCSUG3epCGSOYgkVJs3aYhkDiIJ1eZNGiKZg0hCtXmThkjmIJJQbd6k\nIZI5iCRUmzdpiGQOIgnV5k0aIpmDSEK1eZOGSOYgklBt3qQhkjmIJFSbN2mIZA4iCdXmTRoi\nmYNIQrV5k4ZI5iCSUG3epCGSOYgkVJs3aYhkDiIJ1eZNGiKZYy3SNXRB+vyh/b/Xe/+kxSCS\ndRgoYyxSWv/AUNCaVLx6tBA7F5Gsw0AZW5Eyl5QOXV3S3I1fP9oVi7/fhUjWYaCMrUhx89pW\nmtvr1+9u8g/hIZJ1GCizy2BDI03uos6eXnNdhDeljUiesYdIhYuqm8jlnT295roIb0obkTxj\nD5Gu7v6oLoB+6/bxes3eYpf8/rE3pY1InrGDSHkQP6pxh7jbx+s110Z4U9qI5Bn2IhVBvWMX\nVmPgjT295toIb0obkTzDXqQorP4m9e5dbU+vuTrCm9JGJM+wFikPo7x+0+vwZ8GVYBDJOgyU\nMRbp3gzYIdJv0xDJHFuR8s6j7q1urLkiwpvSRiTPsBUpedv2INJv0hDJHFuR3nfiEOk3aYhk\nzi5ThPQivCltRPIMRBKqzZs0RDIHkYRq8yYNkcxBJKHavElDJHMQSag2b9IQyRxEEqrNmzRE\nMgeRhGrzJg2RzEEkodq8SUMkcxBJqDZv0hDJHEQSqs2bNEQyB5GEavMmDZHMQSSh2rxJQyRz\nEEmoNm/SEMkcRBKqzZs0RDIHkYRq8yYNkcxBJKHavElDJHMQSag2b9IQyRxEEqrNmzREMgeR\nhGrzJg2RzEEkodq8SUMkcxBJqDZv0hDJHEQSqs2bNEQyB5GEavMmDZHMQSSh2rxJQyRzEEmo\nNm/SEMkcRBKqzZs0RDIHkYRq8yYNkcxBJKHavElDJHMQSag2b9IQyRxEEqrNmzREMgeRhGrz\nJg2RzEEkodq8SUMkcxBJqDZv0hDJHEQSqs2bNEQyB5GEavMmDZHMQSSh2rxJG/k8nSHbOv+c\nIJJQbd6kjYm0a5r/IJLQ/96kIZI5iCT0vzdpiGQOIgn9700aIpmDSEL/e5OGSOYgktD/3qQh\nkjmIJPS/N2mIZA4iCf3vTRoimYNIQv97k4ZI5tiLdG1fX6SBC9KibibOJdk3Ed6UNiJ5hrlI\nWTtjJA/q2SNBXrabpmASIlmHIZIy1iJlQStS4tLyb+qS55/4iwhvShuRPMNYpKuLWpF6N4Er\nXg+si/CmtBHJM4xFKjdDrTDtx+uC51PB+FvECG9KG5E8w1ik7LnlubS7dpf2mdRdv4jwprQR\nyTPsR+26XbhrNcQQtPbcXO3V8HULvtHiTWkjkmfsJ9KlNqTdIF3j4LltWhPhTWkjkmfsJtK1\n2gQVyWuHLhH27RDJOgyRlNlNpLAeqitc2D1eCKMNiGQdhkjK7CbS8OatuTjCm9JGJM/YTaTm\n4603Q815pPy1cVoe4U1pI5Jn7CZS6qp5dml1pFTPbChijpF2S0Mkc/YbtYvqUbuoagav5soI\nb0obkTxjP5Ee9ezvZzMUzsciknkYIiljL9I3IJJ1GCIpg0hC/3uThkjmIJLQ/96kIZI5iCT0\nvzdpiGQOIgn9700aIpmDSEL/e5OGSOYgktD/3qQhkjmIJPS/N2mIZA4iCf3vTRoimYNIQv97\nk4ZI5iCS0P/epCGSOYgk9L83aYhkDiIJ/e9NGiKZg0hC/3uThkjmIJLQ/96kIZI5iCT0vzdp\niGQOIgn9700aIpmDSEL/e5OGSOYgktD/3qQhkjmIJPS/N2mIZA4iCf3vTRoimYNIQv97k4ZI\n5iCS0P/epCGSOYgk9L83aYhkDiIJ/e9NGiKZg0hC/3uThkjmIJLQ/96kIZI5iCT0vzdpiGQO\nIgn9700aIpmDSEL/e5OGSOYgktD/3qQhkjmIJPS/N2mIZA4iCf3vTRoimYNIQv97k4ZI5iCS\n0P/epCGSOYgk9L83aYhkDiIJ/e9NGiKZg0hC/3uThkjmIJLQ/96kIZI5iCT0vzdpiGQOIgn9\n700aIpmDSEL/e5OGSOYgktD/3qQhkjmIJPS/N2mIZI69SNfu9dfQBWnx3lwX4U1pI5JnmIuU\nufb1qasIimFzZYQ3pY1InmEtUha0ImUuKarNUzJoro3wprQRyTOMRbq6qBUpbm6qe73m2ghv\nShuRPMNYJJe++dK7h0i7pSGSOcYiZW++FC4aaS6P8Ka0Eckz7EftBiJd3X2k2b6ux+TC7Lof\nkQzT/GdfkfIgHmmuiPCmtBHJM3YVqQiikeaaCG9KG5E8Y1eRonCsuSbCm9JGJM/YUaQ8jPLP\n5roIb0obkTxjP5Hur1G6uzBgJ0d4U9qI5Bm7iZS/5MnnPEIk8zBEUmY3kZLXyHYyN8iNSOZh\niKTMbiL1ThHNni1CJPMwRFLGXqRvQCTrMERSBpGE/vcmDZHMQSSh/71JQyRzEEnof2/SEMkc\nRBL635s0RDIHkYT+9yYNkcxBJKH/vUlDJHMQSeh/b9IQyRxEEvrfmzREMgeRhP73Jg2RzEEk\nof+9SUMkcxBJ6H9v0hDJHEQS+t+bNEQyB5GE/vcmDZHMQSSh/71JQyRzEEnof2/SEMkcRBL6\n35s0RDIHkYT+9yYNkcxBJKH/vUlDJHMQSeh/b9IQyRxEEvrfmzREMgeRhP73Jg2RzEEkof+9\nSUMkcxBJ6H9v0hDJHEQS+t+bNEQyB5GE/vcmDZHMQSSh/71JQyRzEEnof2/SEMkcRBL635s0\nRDIHkYT+9yYNkcxBJKH/vUlDJHMQSeh/b9IQyRxEEvrfmzREMgeRhP73Jg2RzEEkof+9SUMk\ncxBJ6H9v0hDJHEQS+t+bNEQyB5GE/vcmDZHMQSSh/71JQyRzEEnof2/SEMkcRBL635s0RDIH\nkYT+9yYNkcxBJKH/vUlDJHMQSeh/b9IQyRxEEvrfmzREMmdHkbLEuSRv71zFpSCSdRgiKbOf\nSHdXERT1ncwh0o5piGTOfiIFQfYoYpdW7SxApD3TEMmc3US61QoVLnhU+3URIu2Zhkjm7CZS\n4rLXEtIHIu2Zhkjm7CZS6B6XwCX1IVKpFCLtmYZI5uwmknNxPdjwvPv5gh6TS7HrfkQyTNsV\nZ8h06Bfr+eW/rhpsSNylu/tVhDel/X+JZFnav/4g50p2mm9Fqo6Rchd2d7+K8Ka0/zOR7MJ+\n/kHOlew034rUv0GkX/c/IumEzZbsNN+JFCPS79IQySxstmSn+U6ki7s/ql27qF0IIu2Yhkhm\nYbMlO813IpVHR0U12HBrF4JIO6YhklnYbMlO8+Xo5qUeYom6hSDSjmmIZBY2W7LTfHua4B65\nIH0uBJF2TEMks7DZkp1mh/NtiGQdhkhKYbMlOw0inS4NkczCZkt2GkQ6XRoimYXNluw0iHS6\nNEQyC5st2WkQ6XRpiGQWNluy0yDS6dIQySxstmSnQaTTpSGSWdhsyU6DSKdLQySzsNmSnQaR\nTpeGSGZhsyU7DSKdLg2RzMJmS3YaRDpdGiKZhc2W7DSIdLo0RDILmy3ZaRDpdGmIZBY2W7LT\nINLp0hDJLGy2ZKdBpNOlIZJZ2GzJToNIp0tDJLOw2ZKdBpFOl4ZIZmGzJTsNIp0uDZHMwmZL\ndhpEOl0aIpmFzZbsNIh0ujREMgubLdlpEOl0aYhkFjZbstMg0unSEMksbLZkp0Gk06UhklnY\nbMlOg0inS0Mks7DZkp0GkU6XhkhmYbMlOw0inS4NkczCZkt2GkQ6XRoimYXNluw0iHS6NEQy\nC5st2WkQ6XRpiGQWNluy0yDS6dIQySxstmSnQaTTpSGSWdhsyU6DSKdLQySzsNmSnQaRTpeG\nSGZhsyU7DSKdLg2RzMJmS3YaRDpdGiKZhc2W7DSIdLo0RDILmy3ZaRDpdGmIZBY2W7LTINLp\n0hDJLGy2ZKdBpNOlIZJZ2GzJToNIp0tDJLOw2ZKdBpFOl4ZIZmGzJTsNIp0uDZHMwmZLdhpE\nOl0aIpmFzZbsNIh0ujREMgubLdlpEOl0aYhkFjZbstMoiJQGLkiLLyK86ZGf9z8i6YTNluw0\n20WKXEX4RYQ3PfLz/kcknbDZkp1ms0h/LsgeWeD+1kd40yM/739E0gmbLdlpNouUunv59+Yu\n6yO86ZGf9z8i6YTNluw0m0WKXV7+zVy8PsKbHvl5/yOSTthsyU6zWSTn+jerIrzpkZ/3P1Bx\nEwoAAAVhSURBVCLphM2W7DRGIjmAE3MYkQD+LxAJQIHN9R8gEoDWqF0ujNoB+M9mkS71eaS7\nSxVWBuCs7DCzAcB/th/ahPV4YaSwLgCnZbtIRT37W2FVAM4Lg20ACiASgAKIBKAAIgEogEgA\nCiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAA\nIgEocHCRRi6rebVb5fe0InEuyfZK+/r3278I2/Br8V+k1Q9Ed5usireamLsYqwXHFmnkspqZ\n3Y8jf6QF9QNGJr2nZZal/R7WeRTsktY+MH0tuo281cTsxVgtOLRIIz8+Wd6zWuWPtNQl1R+b\nH2P+SJOu1aYe1nC3+VnPj7Sri4pq8270X9JbTfzmJ0sPLdLnZTXLLjET6SMtcNXugVHeR9rV\n7n/sieuTFoGNuh9pUV3UudHPWr/XxPzFWC04tEifl9Us+8JMpImLeBrt/nykXd3VJGg0rH3U\n5jjiI6279I/Nz/G+18T8xVhN1mLXtJV8XnspM7yAzPiVnlKj+v5Ii909sfrJ2tF/WmZ14YOP\nNNtraL3XxG+u2HUykT7uGafd3G7VFju7H1Ef/SCtNkifaWG9jfizK21Ekvm9SNc4MNrXHvlv\n+1b9kLrJBnDsn5ZVQykmfKRdXFw8MrujW0Sa4fcilSQ2+3YTaYXJsO1YWHNMbsFnWn0eIUak\nXzF6WU2zD2jiIp6FzWjD1CVDTf55Y2GBWdd/phXl0d/FsLTH/mGI9GL0sprGo3afF/G0Cdw1\nbSTMcFRr4p+W2Z0jHRm12/tirIcWafSymmYifaQ155Fym/6fTLPo/5EP0nC0feKfdrUr7UFN\n/OZirIcWafQc9c4zG4rYpuJG0tJ6sMHiyGXkg4yt5hlMfZB/YTWaYgMzG2boXVbz+VnZ7ft+\npAWWV/V8TyuaNJv/Rz8/yNBq8Hskrf2n2e1rdTXR3P7kYqzHFql3Wc0dRPpMKx8IrfaAPtIK\nw7TPf5rlsfhHWp6UGhnO/h6K9JOLsR5bJICTgEgACiASgAKIBKAAIgEogEgACiASgAKIBKAA\nIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiAS\ngAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEjHxzWXcvy4JqrhJfBg\nLYh0fFzL29WTQ/ruQNAZx6e5Mmr6fnlhy6vAwlrojOMzcflkRDoSdMbx6UQK6ptr6ILro93h\nK2/vseuu4X2PykMpjpx+AiIdn27XrtLnETcjD0+RLs3xU2XStWlef7qy/yuIdHzcy5XH3UXF\no4jcvfPLudvjcavbQTUccXPhT1f2fwWRjk8rUlSN2sWuKP8WLh4eI9Vt59it+xmIdHwaY+6B\n+3sNhbuXSPn9EtXt1Lk4y4QFgR2IdHxaY7LnkdFApKi7Xx4vBWUjyH+3pv8xiHR8uk1PfzP0\nfDhx4fWedw/f05BjpJ+ASMentaSoxr/j13FQN9hQ/sk//IKd4VM/Po0aRVSN291ckFUD3fVg\nQ14/+ffImmOksBnAY4v0CxDp+HSHRUE1YNccElUHQqGrNlFp++RfPQjetmB3EOn4tBqlRX3v\nWgqUVNuiv7Ce65BUE8Pv1SaqmdmARz8BkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAA\nkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJ\nQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQIF/nlfzmj1BI6oAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Interation vs betas\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot(iternations, main=\"Interation vs betas\", names.arg = successbetas,\n",
    "        ylab = \"Interations\", ylim = c(0,max(iternations)+20), xlab = \"Betas\", axes = FALSE)\n",
    "ylabel <- seq(0, max(iternations)+20, by = max(iternations)%/%10)\n",
    "axis(2, at = ylabel, las = 1)\n",
    "box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation for using Polyak's momentum method\n",
    "\n",
    "There is vast improvement in the alogorithm by using Polyaks Moemtum method. For same alphas number of iteration is reduced to as low as 60 for beta = 0.9. Also we can observe that with beta = 0.9 the cofficients are some what different than with other betas. And as beta>=1 number of iternation increases. I tested for beta  = 1.5 and 2 also for these betas there was no convergenvce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify my coffiecients I did same problem using \"glm\" modelling(shown below). But coffiecients I got for \"glm\" are way too different than coffiecients I got. Is there any specific reason or my implementation is wrong ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Customer</th><th scope=col>HasCard</th><th scope=col>Spends</th><th scope=col>UsesCoupon</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>0        </td><td>8.5815985</td><td>1        </td></tr>\n",
       "\t<tr><td>2        </td><td>0        </td><td>1.4640473</td><td>0        </td></tr>\n",
       "\t<tr><td>3        </td><td>0        </td><td>3.4647250</td><td>0        </td></tr>\n",
       "\t<tr><td>4        </td><td>1        </td><td>0.8019791</td><td>1        </td></tr>\n",
       "\t<tr><td>5        </td><td>0        </td><td>9.9601634</td><td>1        </td></tr>\n",
       "\t<tr><td>6        </td><td>1        </td><td>7.9306165</td><td>1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Customer & HasCard & Spends & UsesCoupon\\\\\n",
       "\\hline\n",
       "\t 1         & 0         & 8.5815985 & 1        \\\\\n",
       "\t 2         & 0         & 1.4640473 & 0        \\\\\n",
       "\t 3         & 0         & 3.4647250 & 0        \\\\\n",
       "\t 4         & 1         & 0.8019791 & 1        \\\\\n",
       "\t 5         & 0         & 9.9601634 & 1        \\\\\n",
       "\t 6         & 1         & 7.9306165 & 1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Customer | HasCard | Spends | UsesCoupon |\n",
       "|---|---|---|---|\n",
       "| 1         | 0         | 8.5815985 | 1         |\n",
       "| 2         | 0         | 1.4640473 | 0         |\n",
       "| 3         | 0         | 3.4647250 | 0         |\n",
       "| 4         | 1         | 0.8019791 | 1         |\n",
       "| 5         | 0         | 9.9601634 | 1         |\n",
       "| 6         | 1         | 7.9306165 | 1         |\n",
       "\n"
      ],
      "text/plain": [
       "  Customer HasCard Spends    UsesCoupon\n",
       "1 1        0       8.5815985 1         \n",
       "2 2        0       1.4640473 0         \n",
       "3 3        0       3.4647250 0         \n",
       "4 4        1       0.8019791 1         \n",
       "5 5        0       9.9601634 1         \n",
       "6 6        1       7.9306165 1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(storeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-1792.18121333074</dd>\n",
       "\t<dt>HasCard</dt>\n",
       "\t\t<dd>1794.90950948725</dd>\n",
       "\t<dt>Spends</dt>\n",
       "\t\t<dd>439.860036489745</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -1792.18121333074\n",
       "\\item[HasCard] 1794.90950948725\n",
       "\\item[Spends] 439.860036489745\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -1792.18121333074HasCard\n",
       ":   1794.90950948725Spends\n",
       ":   439.860036489745\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)     HasCard      Spends \n",
       "  -1792.181    1794.910     439.860 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logitMod <- glm(UsesCoupon ~ HasCard + Spends, data = storeData, family = binomial(link = \"logit\"))\n",
    "coef(logitMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github link for the code \n",
    "\n",
    "https://github.com/jainsanyam786/OptimizationForMachineLearning.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
